{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165b58e0-5457-4ba4-95d5-9efe2016c725",
   "metadata": {},
   "source": [
    "# Single-fact editing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34328a80-4a76-4b74-93c6-d5fa997bdf4b",
   "metadata": {},
   "source": [
    "We inject a counterfactual knowledge edit to our Larimar model using its memory and then quantify if this edit is indeed present, by a subsequent generation.\n",
    "\n",
    "We compare to \"no edit\" (skipping memory) and \"ICL\" (prepending the edit directly to the prompt) setups.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6241cdfa-3c37-41e1-8dd7-532732f8480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c39df9-0f1b-4473-a955-9f76b30719ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from counterfact_eval_rephrase import load_pyrite\n",
    "from counterfact_eval_rephrase import latent_code_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38232c8f-5952-4330-8698-2286f3e2f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e1c939-28d3-4f4e-a605-5791c7a1ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '../models/larimar-1.3b-c3.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a324edf-4356-48e8-a55f-9a2ad65fe088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fddaa2ae-75e5-44cf-9c64-e07828f6e545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemNetLight init()\n",
      "encoder_model_type bert\n",
      "encoder_model_name_or_path bert-large-cased\n",
      "cache_dir ../cache\n",
      "load_pretrained False\n",
      "ParseResult(scheme='https', netloc='s3.amazonaws.com', path='/models.huggingface.co/bert/bert-large-cased-vocab.txt', params='', query='', fragment='')\n",
      "get_from_cache https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt ../cache\n",
      "ParseResult(scheme='https', netloc='s3.amazonaws.com', path='/models.huggingface.co/bert/gpt2-large-vocab.json', params='', query='', fragment='')\n",
      "get_from_cache https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-vocab.json ../cache\n",
      "ParseResult(scheme='https', netloc='s3.amazonaws.com', path='/models.huggingface.co/bert/gpt2-large-merges.txt', params='', query='', fragment='')\n",
      "get_from_cache https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-merges.txt ../cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/16/2025 15:38:44 - INFO - lightning_model -   Added 3 tokens to GPT2\n",
      "You are using a model of type bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForLatentConnector were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['bert.linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2ForLatentConnector were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['linear_emb.weight', 'linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 14.4 s, total: 25.7 s\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, tokenizer = load_pyrite(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6cc228-2cd2-43ee-8f37-9d12cc1339f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tok, dec_tok = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f695a-f161-4a82-a486-f818dceffbcc",
   "metadata": {},
   "source": [
    "This is an example adapted from `CounterFactDataset` (Please refer to `eval_rephrase.sh` for evaluating the full dataset).\n",
    "\n",
    "This is about Danielle Darrieux https://en.wikipedia.org/wiki/Danielle_Darrieux who was a French actor. \n",
    "\n",
    "Our (counterfactual) edit is that Danielle Darrieux was English speaking. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa5d41e-d463-4368-9d8b-a61c613191c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject     = 'Danielle Darrieux'\n",
    "target_true = 'French'\n",
    "target_new  = 'English'\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    'The mother tongue of Danielle Darrieux is',\n",
    "    'Danielle Darrieux was a native',\n",
    "    'Danielle Darrieux spoke the language'\n",
    "]\n",
    "\n",
    "text_write_to_mem = ['The mother tongue of Danielle Darrieux is English']\n",
    "text_to_query     = ['The mother tongue of Danielle Darrieux is']\n",
    "\n",
    "\n",
    "\n",
    "new_fact    = 'The mother tongue of Danielle Darrieux is English.'\n",
    "icl_prompts = [f'{new_fact} {prompt}'\n",
    "               for prompt in prompts\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c299b5-1936-406c-b5d4-03f4eb42b745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The mother tongue of Danielle Darrieux is',\n",
       " 'Danielle Darrieux was a native',\n",
       " 'Danielle Darrieux spoke the language']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dba8673-7f29-4fd8-9540-55e88a31a1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The mother tongue of Danielle Darrieux is English. The mother tongue of Danielle Darrieux is',\n",
       " 'The mother tongue of Danielle Darrieux is English. Danielle Darrieux was a native',\n",
       " 'The mother tongue of Danielle Darrieux is English. Danielle Darrieux spoke the language']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icl_prompts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e93ea41-bb09-4823-a403-c6ec000ef607",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9244e2b0-47b5-49cc-8828-f177c6a660f3",
   "metadata": {},
   "source": [
    "So let's teach our model that Danielle Darrieux's mother tongue was English! \n",
    "\n",
    "In Larimar we can do this without finetuning our model to cater for the new, updated fact we want to introduce to it. All it takes is writing the new fact to Larimar's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453dd809-cbb4-4a4d-a997-e6d3e1b55eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The mother tongue of Danielle Darrieux is English']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_write_to_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ec186-ab19-4ea1-8a92-953bc15c090e",
   "metadata": {},
   "source": [
    "As a first step let's encode the new fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430978c0-5f05-4610-8fe1-042460114eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_write_text_encoded, cls = latent_code_from_text(text_write_to_mem, \n",
    "                                                       enc_tok, \n",
    "                                                       model, \n",
    "                                                       device='cuda')\n",
    "\n",
    "memory_write_text_encoded      = memory_write_text_encoded.reshape(len(text_write_to_mem), \n",
    "                                                                   1, \n",
    "                                                                   model._code_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb39364-bb5e-4687-9954-8f2378eac36f",
   "metadata": {},
   "source": [
    "Then we can write the new fact encoding to Larimar's memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4231f041-4259-4189-9724-36f6987d2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_memory, dkl_M = model.write(input_encoded=memory_write_text_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d096d47-e864-4963-8bca-0bb516ed6338",
   "metadata": {},
   "source": [
    "Let's now see how our model responds when we ask it about Danielle Darrieux. Was she French-speaking (i.e. the original fact) or English speaking (i.e the new fact we just introduced)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794985c-c81a-4eec-83af-fb1c831a5c91",
   "metadata": {},
   "source": [
    "Let's encode our 3 prompts (prefixes) for the purpose of reading from Larimar memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "558250aa-8aed-43d1-9f89-fb2037cd2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes         = prompts\n",
    "enc_tok, dec_tok = tokenizer\n",
    "\n",
    "prefix_lens = []\n",
    "for p in prefixes:\n",
    "    prefix_lens.append(len(dec_tok.encode(p)) + 1)  # +1 for <BOS>\n",
    "\n",
    "encoded_read, cls = latent_code_from_text(prefixes, \n",
    "                                          enc_tok, \n",
    "                                          model, \n",
    "                                          device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b60a7873-4bf9-455e-ba40-87c43f1ff709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_read.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297b33b-2a8a-451d-a17a-54f24841d12f",
   "metadata": {},
   "source": [
    "We use the encoded prompts to get our memory read encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49b5f051-350a-40eb-8fcf-039f7e338547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs, _ = model.read(encoded_read.unsqueeze(1), \n",
    "                   posterior_memory, \n",
    "                   deterministic=True)\n",
    "zs = zs.squeeze()\n",
    "zs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df71f92-df20-423d-b7ee-1dd19f7a7662",
   "metadata": {},
   "source": [
    "With the read encodings on the side we are now ready to investigate whether Larimar thinks that Danielle Darrieux was\n",
    "French speaking or English speaking. \n",
    "\n",
    "We have 3 prompts (prefixes) and each of it can be appended with either \"English\" or \"French\" as an continuation (suffix).\n",
    "We tokenize these 6 statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51cc3175-ed65-48c8-a0a5-1d6f373c8fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The mother tongue of Danielle Darrieux is',\n",
       " 'Danielle Darrieux was a native',\n",
       " 'Danielle Darrieux spoke the language']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57032eb3-14e3-4717-9e3e-27a88e73c188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS>The mother tongue of Danielle Darrieux is English',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is French',\n",
       " '<BOS>Danielle Darrieux was a native English',\n",
       " '<BOS>Danielle Darrieux was a native French',\n",
       " '<BOS>Danielle Darrieux spoke the language English',\n",
       " '<BOS>Danielle Darrieux spoke the language French']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [f'<BOS>{prefix} {suffix}'\n",
    "            for prefix in prefixes\n",
    "            for suffix in [target_new, target_true]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcd47910-aedf-46ae-b565-709d49ead1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tok = pad_sequence([torch.tensor(dec_tok.encode(d), \n",
    "                                        dtype=torch.long) for d in data], \n",
    "                          batch_first=True, \n",
    "                          padding_value=0).to('cuda')\n",
    "len(prompt_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07426a-b7ac-4d9f-8f71-83bee07514e8",
   "metadata": {},
   "source": [
    "Since, we are going to use each of the 3 read encodings from the prompts 2 times (for the \"English\" and the \"French\" statements) we repeat them to accordingly align to the 6 statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9788d573-34f0-40d9-ad83-612c97039d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs = zs.repeat_interleave(2, dim=0)\n",
    "zs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300ec22-32ca-4383-ad56-da7cdd4cc2fa",
   "metadata": {},
   "source": [
    "We are now ready to calculate the mean of `-log(softmax(logits[token])`'s for tokens for \"English\" (new) and for \"French\" (true) as computed by the model, when provided with the prompt and told to do token generation.\n",
    "\n",
    "Larger-likelihood tokens, will correspond to larger logit values and thus larger probabilities (after softmax). Larger probabilities will be represented as powers with smaller magnitude (negative) exponents. \n",
    "\n",
    "These exponent magnitudes are the metrics what we report: smaller is for the tokens the model prefers generating.\n",
    "\n",
    "So if we subtract the metric for \"English\" (new) minus the metric for \"French\" (true), we expect the *difference*  to be negative if the model is indeed updated to the \"new\" knowledge that Danielle Darrieux was \"English\": $\\Delta_{new-true} < 0$\n",
    "(and it will be positive if the model has not incorporated the \"new\" knowledge).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e2b36-1d02-4d09-b88a-e84d333700a5",
   "metadata": {},
   "source": [
    "Let's also calculate some auxiliary quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc1ee395-9f6a-4b0b-ba66-58d0ad4cad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('English', [3594], 1), ('French', [4141], 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tok                      = dec_tok.encode(target_new)\n",
    "b_tok                      = dec_tok.encode(target_true)\n",
    "\n",
    "choice_a_len, choice_b_len = (len(n) for n in [a_tok, b_tok])\n",
    "\n",
    "(target_new, a_tok, choice_a_len), (target_true, b_tok, choice_b_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35cf4c-59f8-493b-9937-31c6b5949b8e",
   "metadata": {},
   "source": [
    "## Unconditional generation in Larimar: Skipping memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f09a0-99da-4ef5-9e6d-608137fb07d9",
   "metadata": {},
   "source": [
    "First let's see how unconditional generation works. Although we have read encodings on the side we do not provide them to Larimar decoder. \n",
    "Our `past` encodings are zero vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cdd6ae0-3e1a-414d-a470-074cb4e77974",
   "metadata": {},
   "outputs": [],
   "source": [
    "past = torch.zeros(zs.shape).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.decoder(prompt_tok, past)[0]\n",
    "\n",
    "results = np.zeros((logits.size(0),), dtype=np.float32)\n",
    "\n",
    "for i in range(logits.size(0)):\n",
    "    cur_len = choice_a_len if i % 2 == 0 else choice_b_len\n",
    "    for j in range(cur_len):\n",
    "        cur_tok = (a_tok if i % 2 == 0 else b_tok)[j]\n",
    "        try:\n",
    "            results[i] += -torch.nn.functional.log_softmax(logits[i, prefix_lens[i // 2] + j - 1, :], dim=0)[cur_tok].item()\n",
    "        except:\n",
    "            continue\n",
    "    results[i] /= cur_len\n",
    "\n",
    "start = len('<BOS>')\n",
    "result_list = [{\"prompt_new\":  data[i][start:],   \"target_new\":  results[i].item(),\n",
    "                \"prompt_true\": data[i+1][start:], \"target_true\": results[i + 1].item()}\n",
    "       for i in range(0, len(results), 2)]\n",
    "\n",
    "\n",
    "unconditional_result_list = result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f196188-3fb2-4394-a4c8-4e3a2eb50201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt_new': 'The mother tongue of Danielle Darrieux is English',\n",
       "  'target_new': 2.936532735824585,\n",
       "  'prompt_true': 'The mother tongue of Danielle Darrieux is French',\n",
       "  'target_true': 0.4290691912174225},\n",
       " {'prompt_new': 'Danielle Darrieux was a native English',\n",
       "  'target_new': 6.317409038543701,\n",
       "  'prompt_true': 'Danielle Darrieux was a native French',\n",
       "  'target_true': 3.8996145725250244},\n",
       " {'prompt_new': 'Danielle Darrieux spoke the language English',\n",
       "  'target_new': 9.241735458374023,\n",
       "  'prompt_true': 'Danielle Darrieux spoke the language French',\n",
       "  'target_true': 8.668529510498047}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unconditional_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3198ece-7138-48d8-8968-fdc40c4e5d6c",
   "metadata": {},
   "source": [
    "We report the list of $\\Delta_{new-true}$'s for the three prompts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f4ea0d8-0201-4972-85bf-6d652a1c85ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5074635446071625, 2.4177944660186768, 0.5732059478759766]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_list = [item['target_new'] - item['target_true'] for item in unconditional_result_list]\n",
    "difference_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88157c73-7681-4e35-be65-d92fa4211294",
   "metadata": {},
   "source": [
    "Larimar model reports smaller values for the \"French\" (true) rather than the \"English\" (new) variant for all our 3 prompts.\n",
    "\n",
    "So unconditional generation in Larimar works as expected: Danielle Darrieux was French, model has not incorporated the \"new\" knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b816279-e04c-44cc-a097-3a89f8d03bc8",
   "metadata": {},
   "source": [
    "## Memory-conditioned generation in Larimar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa3b9e-d24d-48fe-a81b-3128c3739d7e",
   "metadata": {},
   "source": [
    "Let's see how the memory read encodings actually work in Larimar and whether they steer our model towards incorporating the \"new\" knowledge that Danielle Darrieux was English speaking. We just supply memory read encodings as `past` vectors to the decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa84bdac-3e1e-4d50-807d-44c6255be868",
   "metadata": {},
   "outputs": [],
   "source": [
    "past = zs.detach().clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.decoder(prompt_tok, past)[0]\n",
    "\n",
    "results = np.zeros((logits.size(0),), dtype=np.float32)\n",
    "\n",
    "for i in range(logits.size(0)):\n",
    "    cur_len = choice_a_len if i % 2 == 0 else choice_b_len\n",
    "    for j in range(cur_len):\n",
    "        cur_tok = (a_tok if i % 2 == 0 else b_tok)[j]\n",
    "        try:\n",
    "            results[i] += -torch.nn.functional.log_softmax(logits[i, prefix_lens[i // 2] + j - 1, :], dim=0)[cur_tok].item()\n",
    "        except:\n",
    "            continue\n",
    "    results[i] /= cur_len\n",
    "\n",
    "\n",
    "start = len('<BOS>')\n",
    "result_list = [{\"prompt_new\":  data[i][start:],   \"target_new\":  results[i].item(),\n",
    "                \"prompt_true\": data[i+1][start:], \"target_true\": results[i + 1].item()}\n",
    "       for i in range(0, len(results), 2)]\n",
    "\n",
    "\n",
    "conditional_result_list = result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "236e5543-600f-451f-aec3-5ae029a0b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt_new': 'The mother tongue of Danielle Darrieux is English',\n",
       "  'target_new': 3.433168603805825e-05,\n",
       "  'prompt_true': 'The mother tongue of Danielle Darrieux is French',\n",
       "  'target_true': 17.063688278198242},\n",
       " {'prompt_new': 'Danielle Darrieux was a native English',\n",
       "  'target_new': 10.938028335571289,\n",
       "  'prompt_true': 'Danielle Darrieux was a native French',\n",
       "  'target_true': 11.506501197814941},\n",
       " {'prompt_new': 'Danielle Darrieux spoke the language English',\n",
       "  'target_new': 11.552000045776367,\n",
       "  'prompt_true': 'Danielle Darrieux spoke the language French',\n",
       "  'target_true': 15.412997245788574}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79491da-63e0-4c56-bd64-e459ed7cc97e",
   "metadata": {},
   "source": [
    "We report the list of $\\Delta_{new-true}$'s for the three prompts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53357320-5724-4154-a125-7c9443dd5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-17.063653946512204, -0.5684728622436523, -3.860997200012207]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_list = [item['target_new'] - item['target_true'] for item in conditional_result_list]\n",
    "difference_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32c3ac-6685-4854-8ab8-d11b36300603",
   "metadata": {},
   "source": [
    "Larimar model reports smaller values for the \"English\" (new) rather than the \"French\" (true) variant for all our 3 prompts.\n",
    "\n",
    "So conditional generation in Larimar works as expected: Now Danielle Darrieux was updated to being \"English\"-speaking, \n",
    "our model has incorporated the \"new\" knowledge (although it a counterfactual one).\n",
    "\n",
    "In particular for the first prefix (`rewrite prompt`), which is the one that was used in the new knowledge written to Larimar memory, $\\Delta_{new-true}$' is minimal. For the other two prefixes (`paraphrase prompts`) values are less in magnitude but still negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad5051-192d-4387-ba83-ce719aa1c9c7",
   "metadata": {},
   "source": [
    "## ICL setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e01d67-1aa5-465d-a87f-37b4a93a5107",
   "metadata": {},
   "source": [
    "We now assume that we do not have a memory module but we still want to supply the \"new\" knowledge to the model \"directly\", without incurring any additional finetuning costs for the edit (similarly to Larimar's lightweight model editing via memory). \n",
    "\n",
    "We can do this via ICL (In-Context Learning): Our prefixes are appended with the \"new\" knowledge ('The mother tongue of Danielle Darrieux is English.') and then Larimar decoder is used (unconditional generation but with an \"new\"-knowledge informed and longer prefix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ebd8977-8296-43b3-8ffd-508eb0045b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS>The mother tongue of Danielle Darrieux is English. The mother tongue of Danielle Darrieux is English',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is English. The mother tongue of Danielle Darrieux is French',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is English. Danielle Darrieux was a native English',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is English. Danielle Darrieux was a native French',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is English. Danielle Darrieux spoke the language English',\n",
       " '<BOS>The mother tongue of Danielle Darrieux is English. Danielle Darrieux spoke the language French']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fact = 'The mother tongue of Danielle Darrieux is English.'\n",
    "icl_data = [f\"<BOS>{new_fact} {prefix} {suffix}\"\n",
    "            for prefix in prefixes\n",
    "            for suffix in [target_new, target_true]]\n",
    "icl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c869f-330a-4349-a979-52da4e845037",
   "metadata": {},
   "source": [
    "Let's tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce050f90-aca2-444a-8ece-9bcf75a025cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icl_prompt_tok = pad_sequence([torch.tensor(dec_tok.encode(d), \n",
    "                                        dtype=torch.long) for d in icl_data], \n",
    "                          batch_first=True, \n",
    "                          padding_value=0).to('cuda')\n",
    "len(icl_prompt_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7c43a-ea23-4248-abde-160a9ea64ccc",
   "metadata": {},
   "source": [
    "And then compute the ICL prefixes and token lengths needed next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd091a52-9c36-475e-b462-feb198b6e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact = 'The mother tongue of Danielle Darrieux is English.'\n",
    "icl_prefixes = [f\"<BOS>{new_fact} {prefix}\"\n",
    "                for prefix in prefixes]\n",
    "\n",
    "icl_prefix_lens = []\n",
    "for p in icl_prefixes:\n",
    "    icl_prefix_lens.append(len(dec_tok.encode(p)) + 1)  # +1 for <BOS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6867a24d-def6-4d79-808f-3c9cf5ce7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "past = torch.zeros(zs.shape).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.decoder(icl_prompt_tok, past)[0]\n",
    "\n",
    "results = np.zeros((logits.size(0),), dtype=np.float32)\n",
    "\n",
    "for i in range(logits.size(0)):\n",
    "    cur_len = choice_a_len if i % 2 == 0 else choice_b_len\n",
    "    for j in range(cur_len):\n",
    "        cur_tok = (a_tok if i % 2 == 0 else b_tok)[j]\n",
    "        try:\n",
    "            results[i] += -torch.nn.functional.log_softmax(logits[i, icl_prefix_lens[i // 2] + j - 1, :], dim=0)[cur_tok].item()\n",
    "        except:\n",
    "            continue\n",
    "    results[i] /= cur_len\n",
    "\n",
    "start = len('<BOS>')\n",
    "result_list = [{\"prompt_new\":  data[i][start:],   \"target_new\":  results[i].item(),\n",
    "                \"prompt_true\": data[i+1][start:], \"target_true\": results[i + 1].item()}\n",
    "       for i in range(0, len(results), 2)]\n",
    "\n",
    "\n",
    "icl_result_list = result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a45e0db4-d80b-4bf8-83ff-da735349b236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt_new': 'The mother tongue of Danielle Darrieux is English',\n",
       "  'target_new': 7.133586406707764,\n",
       "  'prompt_true': 'The mother tongue of Danielle Darrieux is French',\n",
       "  'target_true': 5.582711219787598},\n",
       " {'prompt_new': 'Danielle Darrieux was a native English',\n",
       "  'target_new': 9.786528587341309,\n",
       "  'prompt_true': 'Danielle Darrieux was a native French',\n",
       "  'target_true': 7.93894100189209},\n",
       " {'prompt_new': 'Danielle Darrieux spoke the language English',\n",
       "  'target_new': 8.760000228881836,\n",
       "  'prompt_true': 'Danielle Darrieux spoke the language French',\n",
       "  'target_true': 6.0284271240234375}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icl_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769ff5a-aa94-4daa-936c-4024c4686179",
   "metadata": {},
   "source": [
    "We report the list of $\\Delta_{new-true}$'s for the three extended prompts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b1aa110-1f93-4828-b56e-f38bae1283d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.550875186920166, 1.8475875854492188, 2.7315731048583984]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_list = [item['target_new'] - item['target_true'] for item in icl_result_list]\n",
    "difference_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27b802-6a10-4217-bc23-04a90c7bbfc2",
   "metadata": {},
   "source": [
    "Prepending the \"new\" knowledge in the prefixes in this setup does not seem to change the signs of $\\Delta_{new-true}$'s, as compared to the unconditional generation, which skips memory (i.e. the case that essentially does no edits). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960864c5-a94a-406b-bf01-d4cac34a08b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
